{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07cc5321-acdc-4ca6-b989-5350fb4496fc",
   "metadata": {},
   "source": [
    "# Set up environment\n",
    "Let's load the basic modules and read the tables from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8115f-9ddd-42a6-a999-8606290c71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.table import Table, QTable\n",
    "from astropy.coordinates import SkyCoord\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd77372-a3e0-44de-81b1-367e93c80171",
   "metadata": {},
   "source": [
    "We will now load the two tables we generated in the last session.\n",
    "- `data1` contains the Gaia query in a rectangle around our region of interest, excluding negative parallaxes.\n",
    "- `cluster1` is our selection on the previous table to filter sources with parallaxes between 5.0 and 5.7 mas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc42bf5-7e4c-454d-ac2a-cd5bafb7b7f8",
   "metadata": {},
   "source": [
    "⚠️ If you want to use the \"official\" `data1` and `cluster1` tables instead of the ones created by yourself do:\n",
    "- open a terminal\n",
    "- Navigate to the data folder  \n",
    "`cd pysnacks_1/tutorials/data`\n",
    "- Delete the files `data1.ecsv` and `cluster1.ecsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed128b8-a24a-486a-a7be-c76e40685899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for my_file in ['data1', 'cluster1']:\n",
    "    if not os.path.isfile(f'../data/{my_file}.ecsv'):\n",
    "        print(f'Using official {my_file} file')\n",
    "        os.system(f'unzip ../data/backup/{my_file}.ecsv.zip')\n",
    "        os.system(f'mv {my_file}.ecsv ../data')\n",
    "    else:\n",
    "        print(f'Doing nothing because ../data/{my_file}.ecsv already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10cc18-3219-45d5-81ae-c67803f88166",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = Table.read('../data/data1.ecsv')\n",
    "cluster1 = Table.read('../data/cluster1.ecsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35bf2e-dc3f-4906-b177-1a98b54cd2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variables(data, col1, col2, ax, **kwargs):\n",
    "    \n",
    "    pl = ax.scatter(data[col1], data[col2], **kwargs)\n",
    "\n",
    "    description1 = data1[col1].description        # Obtain column 1 description\n",
    "    unit1 = data1[col1].unit                      # Obtain column 1 units\n",
    "    description2 = data1[col2].description        # Obtain column 2 description\n",
    "    unit2 = data1[col2].unit                      # Obtain column 2 units\n",
    "\n",
    "    ax.set_xlabel(f\"{description1} [{unit1}]\") # Set the axis label in the form \"Variable description [units]\"\n",
    "    ax.set_ylabel(f\"{description2} [{unit2}]\") # Set the axis label in the form \"Variable description [units]\"\n",
    "\n",
    "    ax.legend()\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8ce6d-9f4f-4e22-839b-84367d605a15",
   "metadata": {},
   "source": [
    "# Introduction to scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fec149-44ea-4e26-9654-1120cff5b3e8",
   "metadata": {},
   "source": [
    "[scikit-learn](https://scikit-learn.org/) is a library for Machine Learning in Python. \n",
    "We will work with a couple of [clustering algorithms](https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py): [K-means clustering](https://scikit-learn.org/stable/modules/clustering.html#k-means) (you can find an example [here](https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html#sphx-glr-auto-examples-cluster-plot-cluster-iris-py)) and [DBSCAN](https://scikit-learn.org/stable/modules/clustering.html#dbscan) (you can find an example [here](https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html?highlight=example%20dbscan))   \n",
    "\n",
    "![image](../data/sphx_glr_plot_cluster_comparison_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34063407-441b-4f04-bea9-25783b9fa653",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "We need an array of size NxM, with N the number of rows and M the number of features (or columns, or variables). We will forget about the units and work with plain numpy arrays. We will create a numpy array from three of the columns we want. However, note that that array would be of size 3 x 23050, so we need to transpose it with method `.T`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d6aad6-b08a-4891-afa0-6ce2ebb45bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tmp = np.array([data1['pmra'],\n",
    "                    data1['pmdec'], \n",
    "                    data1['parallax']\n",
    "                   ])\n",
    "pos_tmp.shape   # We cannot use this, we need to transpose the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1becfda9-a45a-4655-83d1-dda123774d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pos_tmp.T\n",
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80735fe1-7033-4062-ad11-b986dfcec0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3129e66-34e1-4b79-a2e9-7c5f65c34ed5",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2ad6c-e835-4587-aa37-0133ba94cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb609d1-11eb-4627-949f-2b35d3cb4aa9",
   "metadata": {},
   "source": [
    "We can learn more about this functions by running:\n",
    "\n",
    "```python\n",
    "KMeans?\n",
    "\n",
    "    KMeans(\n",
    "        n_clusters=8,\n",
    "        *,\n",
    "        init='k-means++',\n",
    "        n_init=10,\n",
    "        max_iter=300,\n",
    "        tol=0.0001,\n",
    "        verbose=0,\n",
    "        random_state=None,\n",
    "        copy_x=True,\n",
    "        algorithm='auto',\n",
    "    )\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253c31f9-a584-46dd-930a-4c9dad7b2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "KMeans?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bfa4cb-4413-4c05-b6ae-d212b4efd72b",
   "metadata": {},
   "source": [
    "[K-means vlustering visualization](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73841fd-ae30-4b9d-aa7f-f6b614cc5402",
   "metadata": {},
   "source": [
    "Let's run the algorithm trying to search for three clusters, using `n_clusters=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c67db3-d3c8-4eeb-a55f-0befb4575123",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)    # We initialize the algorithm\n",
    "kmeans.fit(pos)                  # We conduct the fit\n",
    "labels = kmeans.predict(pos)     # We extract the labels with the classification\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579e4fd-1e58-45a4-bc54-1dd2e87f03f8",
   "metadata": {},
   "source": [
    "The `labels` can be 0, 1 or 2, and there is one label for each star (in total 23050). Let's see how many stars are in each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b33be6-2a93-4387-acc4-c303be598c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels, bins = np.arange(-0.25, 2.4, 0.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d40f7-7727-4bff-95d3-0bb041fd2e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8686b-2888-485d-bf36-8546eb473eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = 'pmra'\n",
    "col2 = 'pmdec'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,10))   # We can select ncols, nrows, or both.\n",
    "\n",
    "plot_variables(data1[labels==0], col1, col2, ax, s=8, alpha=0.8, label='Group 0')\n",
    "plot_variables(data1[labels==1], col1, col2, ax, s=8, alpha=0.8, label='Group 1')\n",
    "plot_variables(data1[labels==2], col1, col2, ax, s=8, alpha=0.8, label='Group 2')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-60, 30)\n",
    "ax.set_ylim(-60, 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a344e-2671-4cbb-8212-ef7dacf72bd9",
   "metadata": {},
   "source": [
    "Later we will see why we get the result, for the moment, try to find the cluster using more clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758df23d-271d-4e25-b15a-ab2ad879c83b",
   "metadata": {},
   "source": [
    "### ⛏ Exercise 4.1\n",
    "Run the KMeans algorithm again but with selecting 10 clusters `n_clusters=10`.\n",
    "\n",
    "Tip: when you plot the results, you can use a `for` loop to avoid writing to much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14021c0-727f-4384-8ca9-a8f881affd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306c333-c027-4d6a-8938-a58de0b0c6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e6f70e8-b2b1-4411-8291-a272ceb7d87f",
   "metadata": {},
   "source": [
    "This is quite dissapoining. This is more useful for cutting a pizza than for finding clusters. The main problems are:\n",
    "- This is a purely geometric method, so that is what we get: geometric cuts\n",
    "- The proper motion values are much larger (about 40 mas/yr) and the parallax values (about 5 mas), so the parallax is not contributing\n",
    "\n",
    "What we really need to do is to normalize the variables so they have comparable value scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62175eff-af53-4e84-9c5f-98b6462a580b",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "\n",
    "For K-Means Clustering, the Euclidean distance is important, so Feature Scaling makes a huge impact. We can use `StandardScaler` to regularize the data so each feature has mean = 0 and standard deviation = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e1a580-e771-447f-b800-bed15b900ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#StandardScaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c8c0b-2f20-43d5-8c7b-be56745322d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pos_norm = scaler.fit_transform(pos)\n",
    "pos_norm    # Now all values are comparable and close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a17bd-a1ad-42a5-add6-3b28611fbbf7",
   "metadata": {},
   "source": [
    "Let's quickly compare the mean and standard deviations before and after the normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bfd744-20a0-4691-9fd3-2de2e7a0955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before scaling:')\n",
    "print(f\"Mean: {pos.mean(axis=0)}\")\n",
    "print(f\"Std:  {pos.std(axis=0)}\")\n",
    "print('\\nAfter scaling:')\n",
    "print(f\"Mean: {pos_norm.mean(axis=0)}\")\n",
    "print(f\"Std:  {pos_norm.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ec168-a7ec-4147-b08a-7468b26d5791",
   "metadata": {},
   "source": [
    "We are ready to execute again the algorithm but using `pos_norm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c9a89-bf11-4b77-b532-424744b6fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)          # We initialize the algorithm\n",
    "kmeans.fit(pos_norm)                   # We conduct the fit\n",
    "labels_norm = kmeans.predict(pos_norm) # We extract the labels with the classification\n",
    "labels_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb5078-1106-4a0a-8c99-02ad38ed5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = 'pmra'\n",
    "col2 = 'pmdec'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,10))   # We can select ncols, nrows, or both.\n",
    "\n",
    "for label in range(3):\n",
    "    plot_variables(data1[labels_norm==label], col1, col2, ax, s=8, alpha=0.8, label=f\"Group {label}\")\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-60, 30)\n",
    "ax.set_ylim(-60, 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc56854-4e49-4882-b01e-57a290e8f306",
   "metadata": {},
   "source": [
    "Not really what we are looking for. It is purely forcing the groups to follow linear distance, without taking into consideration the density, and that means that many outlier stars are included in the orange group simply because it is the closer group. We need to find an alternative method!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cda553-2f4a-4bd7-b4c9-2d09166dd5b9",
   "metadata": {},
   "source": [
    "## DBSCAN: Density-Based Spatial Clustering of Aplications with Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840f8de-e70f-482d-ba51-bebc3b48a229",
   "metadata": {},
   "source": [
    "[DBSCAN visualization](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3aba6b-0efd-4886-981d-4c7ffbe0be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0965838-7135-4372-adac-8cdf17b9b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=1.2, min_samples=60, metric='euclidean').fit(pos)\n",
    "labels_dbscan = db.labels_\n",
    "labels_dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63dfb5-8c87-460a-a3e0-a6555e353049",
   "metadata": {},
   "source": [
    "We can use `set` to remove duplicates so we can see the unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43f104-7a63-46e8-9299-cf3af14b9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(labels_dbscan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7df4d9-c184-4767-9838-073f9a31aa7e",
   "metadata": {},
   "source": [
    "Labeled as -1 for “noise”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf2001-547f-4445-9cdb-d2009ee746d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = 'pmra'\n",
    "col2 = 'pmdec'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,10))   # We can select ncols, nrows, or both.\n",
    "\n",
    "plot_variables(data1[labels_dbscan==label], col1, col2, ax, s=5, c='k', alpha=0.5, label=f\"Group {label}\")\n",
    "for label in list(set(labels_dbscan)):\n",
    "    if label > -1:\n",
    "        plot_variables(data1[labels_dbscan==label], col1, col2, ax, s=8, alpha=0.8, label=f\"Group {label}\")\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-60, 30)\n",
    "ax.set_ylim(-60, 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8098868-e46d-4b77-8f0b-9021f87df784",
   "metadata": {},
   "source": [
    "Let's now use `pos_norm` instead of `pos` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bd7d8-f1f3-4892-8673-ed102320ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_norm = DBSCAN(eps=0.12, min_samples=50, metric='euclidean').fit(pos_norm)\n",
    "labels_dbscan_norm = db_norm.labels_\n",
    "labels_dbscan_norm\n",
    "print(set(labels_dbscan_norm))\n",
    "\n",
    "col1 = 'pmra'\n",
    "col2 = 'pmdec'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,10))   # We can select ncols, nrows, or both.\n",
    "\n",
    "plot_variables(data1[labels_dbscan_norm==label], col1, col2, ax, s=5, c='k', alpha=0.5, label=f\"Group {label}\")\n",
    "for label in list(set(labels_dbscan_norm)):\n",
    "    if label > -1:\n",
    "        plot_variables(data1[labels_dbscan_norm==label], col1, col2, ax, s=8, alpha=0.8, label=f\"Group {label}\")\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-60, 30)\n",
    "ax.set_ylim(-60, 30);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6e124-c47e-44b2-bac6-7d906819021c",
   "metadata": {},
   "source": [
    "We can count how many members are in the orange cluster by selecting from `data1` only those stars labelled with label 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c365197-80b8-493f-8d2f-39ef955d1904",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data1[labels_dbscan_norm==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573f2e4-242b-47f4-8520-14f181fc982c",
   "metadata": {},
   "source": [
    "We can show the distribution for the three relevant columns and where the clusters are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd760860-0086-4560-b710-5c8e19143e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pmra', 'pmdec', 'parallax']\n",
    "bins = [\n",
    "    np.arange(-50, 30, 0.5),\n",
    "    np.arange(-40, 20, 0.5),\n",
    "    np.arange(0, 7, 0.05)\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, figsize=(10, 18))\n",
    "\n",
    "for col, ax, bin in zip(cols, axs, bins):\n",
    "    ax.hist(data1[col], bins=bin, color='grey', label='Full sample')\n",
    "\n",
    "    # We iterate now over all the clusters found\n",
    "    for label in list(set(labels_dbscan_norm)):\n",
    "        if label > -1:\n",
    "            ax.hist(data1[labels_dbscan_norm==label][col], bins=bin, label=f'Cluster DBSCAN {label}')\n",
    "\n",
    "    description = data1[col].description\n",
    "    unit = data1[col].unit\n",
    "\n",
    "    ax.set_xlabel(f\"{description} [{unit}]\")\n",
    "    ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae74f1a-1a7a-4dab-9512-32c28a356422",
   "metadata": {},
   "source": [
    "We can also compare the parallax distribution of the `cluster1` we manually selected vs the DBSCAN one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a76ff7-1b7f-4e3b-9bca-9e2bebe6ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = 'parallax'\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(18,6))\n",
    "\n",
    "# Left panel original cluster1 with a manual cut in parallax\n",
    "ax[0].hist(data1[col1],    bins=np.arange(4, 7, 0.03), label='Full sample')\n",
    "ax[0].hist(cluster1[col1], bins=np.arange(4, 7, 0.03), label='Cluster 1')\n",
    "\n",
    "# Right panel with the cluster found with DBSCAN\n",
    "ax[1].hist(data1[col1], bins=np.arange(4, 7, 0.03), label='Full sample')\n",
    "label = 1  # We are focusing now in our cluster\n",
    "ax[1].hist(data1[labels_dbscan_norm==label][col1], bins=np.arange(4, 7, 0.03), label=f'Cluster DBSCAN {label}')\n",
    "\n",
    "description = data1[col1].description\n",
    "unit = data1[col1].unit\n",
    "\n",
    "ax[0].set_xlabel(f\"{description} [{unit}]\")\n",
    "ax[1].set_xlabel(f\"{description} [{unit}]\")\n",
    "ax[0].legend()\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2ef81-8cef-42ba-bdfd-4ffc2999a31d",
   "metadata": {},
   "source": [
    "## Save the new cluster as `cluster2`\n",
    "\n",
    "We are happy with the cluster selection using DBSCAN, so we will create a new table and save it on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b4bf3-ffc5-487e-83f5-4390e370b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2 = data1[labels_dbscan_norm==1]\n",
    "cluster2.write('../data/cluster2.ecsv', format='ascii.ecsv', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2384ad0d-ab3a-4a12-8e6b-a0cd23bf614d",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Can we measure the age of the cluster?\n",
    "\n",
    "The general method we will use to estimate the age of our cluster is to identify the isochrone tha better fits the turnover between the line of main sequence stars and the red giant branch. A general description of the method is described in [Measuring the Age of a Star Cluster](https://www.e-education.psu.edu/astro801/content/l7_p6.html).\n",
    "\n",
    "The method is also described in this SEA proceedings: [Rio et al 2014](https://www.sea-astronomia.es/sites/default/files/archivos/proceedings11/via_lactea/rioj/rioj.pdf)\n",
    "\n",
    "![myimage.gif](../data/HR_age.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef207c-8a8a-4ea2-93f6-e3b039d68f0a",
   "metadata": {},
   "source": [
    "Although Gaia does not provide the most accurate photometry, it is equiped with three filters that are good enough for our first analysis. The variables we want to use are:\n",
    "- `bp_rp`: The BP - RP colour computed from the Blue Passband and the Red Passband \n",
    "- `Mg`: The absolute magnitude we computed using the apparent magnitude `phot_g_mean_mag` and the `parallax`\n",
    "\n",
    "And we can also use a couple other variables to make the plots more interesting:\n",
    "- `dr2_rv_template_teff`\n",
    "\n",
    "![image.png](../data/GaiaDR2Passbands.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0a08d-34de-4083-b6c6-bf2fda52e846",
   "metadata": {},
   "source": [
    "First, let's count how many stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38638af0-691e-4389-98ac-4ce7bcc49706",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of stars in the cluster: {np.count_nonzero(cluster2)}\")\n",
    "\n",
    "print(f\"Number of stars with bp_rp values: {np.count_nonzero(cluster2['bp_rp'])}\")\n",
    "print(f\"Number of stars with Mg values: {np.count_nonzero(cluster2['bp_rp'])}\")\n",
    "print(f\"Number of stars with dr2_rv_template_teff values: {np.count_nonzero(cluster2['dr2_rv_template_teff'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38255b2a-d880-4336-9417-58fa10ebdc26",
   "metadata": {},
   "source": [
    "First we will create a HR-diagram for all stars in the original sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55a80a-80f7-4f3b-a001-062310892337",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "\n",
    "plot_variables(data1, 'bp_rp', 'Mg', ax, c='grey', s=1, label='Full sample')\n",
    "\n",
    "ax.set_ylabel('Absolute magnitude')   # We didn't write description and units to the original table\n",
    "\n",
    "ax.set_xlim(-0.5, 3.6)\n",
    "ax.set_ylim(15, -2.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8793fe2-e352-41ea-b185-77c6659457dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "\n",
    "plot_variables(data1,    'bp_rp', 'Mg', ax, c='grey', s=1, label='Full sample')\n",
    "plot_variables(cluster2, 'bp_rp', 'Mg', ax, c='k', s=50, label='Cluster2')\n",
    "\n",
    "ax.set_ylabel('Absolute magnitude')   # We didn't write description and units to the original table\n",
    "\n",
    "ax.set_xlim(-0.5, 3.6)\n",
    "ax.set_ylim(15, -2.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df8745-b99a-4122-938a-6233c36ed088",
   "metadata": {},
   "source": [
    "Note: can you identify the binary stellar systems in the plot? And the white dwarfs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb7988-41f9-411b-9bf9-fdbd5a90b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,12))\n",
    "\n",
    "plot_variables(data1,    'bp_rp', 'Mg', ax, c='grey', s=1, label='Full sample')\n",
    "plot_variables(cluster2, 'bp_rp', 'Mg', ax, c='k', s=50)\n",
    "pl = plot_variables(cluster2, 'bp_rp', 'Mg', ax, c=cluster2['dr2_rv_template_teff'], s=50, label='Cluster2')\n",
    "\n",
    "ax.set_ylabel('Absolute magnitude G')   # We didn't write description and units to the original table\n",
    "\n",
    "cb = fig.colorbar(pl)\n",
    "cb.set_label(\"$T_{eff}$ [K]\")\n",
    "\n",
    "ax.set_xlim(-0.5, 3.6)\n",
    "ax.set_ylim(15, -2.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e07ffc5-586f-487b-8a9b-16cf13b7b38a",
   "metadata": {},
   "source": [
    "# Isochrones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8e4b9-9b22-4e61-a205-301da81ca493",
   "metadata": {},
   "source": [
    "[Stellar isochrones](https://en.wikipedia.org/wiki/Stellar_isochrone) are curves in the Hertzsprung-Russell computed using stellar evolution models that represent a population of stars of the same age but with different mass.\n",
    "\n",
    "![image.png](../data/Isochrones_of_several_ages.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2378c57a-5141-4dd2-9f9f-78426fcae6c2",
   "metadata": {},
   "source": [
    "How to obtain already computed isochrones? It is not straightforward, because many possible curves can be simulated using stellar population synthesis modeling over large grids of stellar parameters like mass, metallicity, size, gravity, etc. Some packages are able to simulate stellar populations based on these templates, for example:\n",
    "- [SPISEA: Stellar Population Interface for Stellar Evolution and Atmospheres](https://github.com/astropy/SPISEA) PySnacks 2!\n",
    "- [isochrones](https://isochrones.readthedocs.io/en/latest/) library\n",
    "\n",
    "Both are based on the MESA Isochrones & Stellar Tracks ([MIST](http://waps.cfa.harvard.edu/MIST/)) database. They provide a very useful web interface to generate isochrones: [Isochrone Interpolation](http://waps.cfa.harvard.edu/MIST/interp_isos.html). We generated a grid of isocrhones for a wide range of ages based on standard stellas paramters.\n",
    "\n",
    "In particular, we are going to use the file `pysnacks1/data/MIST_iso_62321da9c816b.iso.cmd` that is already uploaded in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522adf8-a181-41e4-9f5c-7b38efe72386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New\n",
    "import os\n",
    "filename = '../data/MIST_iso_6245f451cfcaf.iso.cmd'\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "    os.system(\"cd ../data && unzip MIST_iso_6245f451cfcaf.iso.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1683ef7-0562-4323-b488-d02479f3a069",
   "metadata": {},
   "source": [
    "Great, now we have our isochrones ready, but to load them we need to use a special script to be able to read the cmd format.\n",
    "\n",
    "The Github repository [MIST_codes](https://github.com/jieunchoi/MIST_codes) provides routines to run and process a grid of MIST models. In particular we want the `read_mist_models.py` script to be able to load MIST models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16fea6-3ed3-4613-93a0-54a359b20031",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('read_mist_models.py'):\n",
    "    os.system('curl -O https://raw.githubusercontent.com/jieunchoi/MIST_codes/master/scripts/read_mist_models.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c17be-fa65-4b03-b963-12bd667d2c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_mist_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034c826-2edd-4df2-8f54-324e693d5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "isocmd = read_mist_models.ISOCMD(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2611a185-4259-4e37-8136-5439c41f929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('version: ', isocmd.version)\n",
    "print('abundances: ', isocmd.abun)\n",
    "print('rotation: ', isocmd.rot)\n",
    "print('ages: ', [round(x,2) for x in isocmd.ages])\n",
    "print('number of ages: ', isocmd.num_ages)\n",
    "print('available columns: ', isocmd.hdr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ee8d6-68c6-4143-b201-55997dbcea20",
   "metadata": {},
   "source": [
    "We can access the isochrone for a specific age selecting the age index and the column:\n",
    "\n",
    "```python\n",
    "age_ind = isocmd.age_index(age)       # returns the index for the desired age\n",
    "isocmd.isocmds[age_ind][column_name]\n",
    "```\n",
    "\n",
    "For example to obtain the isocrhone corresponding to the Gaia EDR3 G band for an log10(age) of 8.0, que can do:\n",
    "\n",
    "```python\n",
    "age_ind = isocmd.age_index(8.0)       # returns the index for the desired age\n",
    "isocmd.isocmds[age_ind]['Gaia_G_EDR3']\n",
    "```\n",
    "\n",
    "It is also possible to select different stellar evolutionary stages by creating a mask. To select stars in the main sequence and red giant phases we can create this mask:\n",
    "```python\n",
    "phase_mask = (isocmd.isocmds[age_ind]['phase'] >= 0) & (isocmd.isocmds[age_ind]['phase'] < 3)\n",
    "isocmd.isocmds[age_ind]['Gaia_G_EDR3'][phase_mask]\n",
    "```\n",
    "More details on how to use MIST synthetic profiles can be found [here](https://datacarpentry.org/astronomy-python/calculating_MIST_isochrone/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb222c-6d63-4b43-ba10-baad3b7f606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ind = isocmd.age_index(8.0)       # returns the index for the desired age\n",
    "isocmd.isocmds[age_ind]['Gaia_G_EDR3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c49720b-1a52-467b-9e88-96282bd22b2e",
   "metadata": {},
   "source": [
    "As an example, we can plot the isochrone corresponding to log10(age) = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfac49-86ad-4aaf-a092-ef9a309fb8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,12))\n",
    "\n",
    "plot_variables(data1,    'bp_rp', 'Mg', ax, c='grey', s=1, label='Full sample')\n",
    "plot_variables(cluster2, 'bp_rp', 'Mg', ax, c='k', s=50)\n",
    "pl = plot_variables(cluster2, 'bp_rp', 'Mg', ax, c=cluster2['dr2_rv_template_teff'], s=50, label='Cluster2')\n",
    "\n",
    "ax.set_ylabel('Absolute magnitude G')   # We didn't write description and units to the original table\n",
    "\n",
    "cb = fig.colorbar(pl)\n",
    "cb.set_label(\"$T_{eff}$ [K]\")\n",
    "\n",
    "ax.set_xlim(-0.5, 3.6)\n",
    "ax.set_ylim(15, -2.5)\n",
    "\n",
    "age = 9\n",
    "age_ind = isocmd.age_index(age) #returns the index for the desired age\n",
    "BP = isocmd.isocmds[age_ind]['Gaia_BP_EDR3']\n",
    "RP = isocmd.isocmds[age_ind]['Gaia_RP_EDR3']\n",
    "G  = isocmd.isocmds[age_ind]['Gaia_G_EDR3']\n",
    "ax.plot(BP-RP, G, label=\"age\", lw=2) \n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65fc2a-46fe-4195-91e0-b42700af353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(14,12))\n",
    "\n",
    "ax.scatter(data1['bp_rp'], data1['Mg'], c='grey', s=1)\n",
    "ax.scatter(cluster2['bp_rp'], cluster2['Mg'], c='k', s=40)\n",
    "l = plt.scatter(cluster2['bp_rp'], cluster2['Mg'], c=cluster2['dr2_rv_template_teff'], s=40)\n",
    "\n",
    "ax.set_ylabel('Absolute magnitude G')   # We didn't write description and units to the original table\n",
    "\n",
    "cb = fig.colorbar(l)\n",
    "cb.set_label(\"$T_{eff}$ [K]\")\n",
    "\n",
    "ax.set_xlim(-0.5, 3.6)\n",
    "ax.set_ylim(15, -2.5)\n",
    "\n",
    "for age in [8.7, 8.8, 8.9, 9.0, 9.1]:\n",
    "    age_ind = isocmd.age_index(age) #returns the index for the desired age\n",
    "    BP = isocmd.isocmds[age_ind]['Gaia_BP_EDR3']\n",
    "    RP = isocmd.isocmds[age_ind]['Gaia_RP_EDR3']\n",
    "    G  = isocmd.isocmds[age_ind]['Gaia_G_EDR3']\n",
    "    ax.plot(BP-RP, G, label=age, lw=2) \n",
    "\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f2b1f-13a9-4396-8d83-df347d31004f",
   "metadata": {},
   "source": [
    "### ✨ Exercise 4.2\n",
    "\n",
    "Estimate the age of the cluster. Although we are not going to fit the isochrone to the data, we can estimage the age of the cluster by selecting the isochrone that better approaches the data, in particular the red giant turnover. Remember that the isochrones are identified by the log10 of the age. Complete this code to find the age of the cluster in Myr.\n",
    "```python\n",
    "age_cluster2 = 10**<your preferred isochrone>*u.yr    # Select a number between 8.7 and 9.1\n",
    "print(f\"The age of the cluster is approximately {age_cluster2.to('Myr'):5.3f}\") \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61caab4f-3169-43dd-86e7-b74763d88dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffd434b7-229a-49e9-add3-2e0de91db353",
   "metadata": {},
   "source": [
    "### ✨ Exercise 4.3:  Summary of final results\n",
    "\n",
    "- Convert the table `cluster2` to into a QTable with `QTable(cluster2)`\n",
    "- Print all the relevant values you found for this cluster:\n",
    "  - Number of members\n",
    "  - Mean R.A. (in hms) and Dec. (in dms)\n",
    "  - Mean proper motion in R.A. and Dec. in mas/yr\n",
    "  - Mean parallax in mas and mean distance in pc.\n",
    "\n",
    "Tip 1: To make everything easier, work with a Qtable: `c = QTable(cluster2)`  \n",
    "Tip 2: Define an SkyCoord object using `ra` and `dec` columns and print them with `coord.ra.to_string()`, `coord.dec.to_string()`  \n",
    "Tip 3: Use prints similar to `print(f\"Proper motion R.A. : {c['pmra'].mean():5.1f}\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab63f5-60ce-4be3-a54b-9684447dd392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ce193-668b-451b-a671-5bbb4092dd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb544a0d-b621-49ab-8ead-1c1098db4a65",
   "metadata": {},
   "source": [
    "### 🌪 Exercise\n",
    "Write the results as a latex table with two columns: variable name and value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81917cff-14c2-4f64-838a-8e011d79c488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb9685-7640-460f-9bff-e0e409eaadfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f98eba4-931f-4fbb-a99e-89976ea8d635",
   "metadata": {},
   "source": [
    "### 🌪 Exercise\n",
    "Compare the number of members, proper motions and distance values we obtained with the ones in Vizier table: J/A+A/633/A99/table1\n",
    "\n",
    "You have two options:  \n",
    "(a) Download the Vizier table with `astroquery` as explained the first day  \n",
    "(b) Simply visit https://vizier.cds.unistra.fr/viz-bin/VizieR-5?-ref=VIZ6232587c2323a1&-out.add=.&-source=J/A%2bA/633/A99/table1&recno=834\n",
    "\n",
    "What is our discrepancy in the distance of the cluster with respect to that publication?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c2d9b-1d77-44a4-9a32-147090f0776d",
   "metadata": {},
   "source": [
    "### 🌪 Exercise\n",
    "Try to improve the proper motion of the cluster by computing the weighted average of the `pmra` and `pmdec` columns. You can do it by converting the column to a numpy array with the `.data` attribute, and then applying `np.average`. Check the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bf9e2c-78e2-4692-ae60-e90f92a68609",
   "metadata": {},
   "source": [
    "### 🌪 Exercise\n",
    "The [Simbad page for NGC 2632 / M44](https://simbad.u-strasbg.fr/simbad/sim-basic?Ident=m44) indicates that:\n",
    "\n",
    "> Angular size (arcmin): \t118.2 118.2 0 (Opt) D [2020A&A...633A..99C ](https://simbad.cds.unistra.fr/simbad/sim-ref?bibcode=2020A%26A...633A..99C)\n",
    "\n",
    "Compute the physical size of `cluster2` following the criteria of the paper. Or at least, compute the maximum separation between stars in `cluster2`.\n",
    "\n",
    "- Looking at that size of the cluster, did we made a good choice when we queried a region of 3 x 2 deg? Could that explain that the number of members we found is smaller than the 697 detected in [this publication](https://vizier.cds.unistra.fr/viz-bin/VizieR-5?-ref=VIZ6232587c2323a1&-out.add=.&-source=J/A%2bA/633/A99/table1&recno=834)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115039c-447a-4e90-8e2d-e06063932396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
